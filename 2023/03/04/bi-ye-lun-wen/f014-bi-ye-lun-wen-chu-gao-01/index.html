<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Aegis | Aegis</title><meta name="author" content="Deng"><meta name="copyright" content="Deng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="系统设计功能设计录入新员工功能包括:   获取新员工信息,   训练模型;    打卡功能包括:   加载训练模型,   获取人脸图片,   识别人脸;       录入新员工功能 录取新员工首先要获取新员工的信息,   包括姓名与人脸图片，首先需要打开摄像头，从摄像头中不断捕捉图像帧，检测到捕捉的图像帧有人脸信息之后，才将图片存入人脸；将图片存入本地之后，需要对存入的图片进行训练，将得到训练模型">
<meta property="og:type" content="article">
<meta property="og:title" content="Aegis">
<meta property="og:url" content="http://example.com/2023/03/04/bi-ye-lun-wen/f014-bi-ye-lun-wen-chu-gao-01/index.html">
<meta property="og:site_name" content="Aegis">
<meta property="og:description" content="系统设计功能设计录入新员工功能包括:   获取新员工信息,   训练模型;    打卡功能包括:   加载训练模型,   获取人脸图片,   识别人脸;       录入新员工功能 录取新员工首先要获取新员工的信息,   包括姓名与人脸图片，首先需要打开摄像头，从摄像头中不断捕捉图像帧，检测到捕捉的图像帧有人脸信息之后，才将图片存入人脸；将图片存入本地之后，需要对存入的图片进行训练，将得到训练模型">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg">
<meta property="article:published_time" content="2023-03-04T12:37:32.084Z">
<meta property="article:modified_time" content="2023-04-03T08:36:44.128Z">
<meta property="article:author" content="Deng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/03/04/bi-ye-lun-wen/f014-bi-ye-lun-wen-chu-gao-01/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":50},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Aegis',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-03 16:36:44'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.1"><link rel="alternate" href="/atom.xml" title="Aegis" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.picsum.photos/id/145/4288/2848.jpg?hmac=UkhcwQUE-vRBFXzDN1trCwWigpm7MXG5Bl5Ji103QG4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">168</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Aegis</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">无题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label"></span><time class="post-meta-date-created" datetime="2023-03-04T12:37:32.084Z" title=" 2023-03-04 20:37:32">2023-03-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label"></span><time class="post-meta-date-updated" datetime="2023-04-03T08:36:44.128Z" title=" 2023-04-03 16:36:44">2023-04-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h1><h2 id="功能设计"><a href="#功能设计" class="headerlink" title="功能设计"></a>功能设计</h2><p>录入新员工功能包括:   获取新员工信息,   训练模型;   </p>
<p>打卡功能包括:   加载训练模型,   获取人脸图片,   识别人脸;   </p>
<img src="D:/Program%20Files/Typora/img/image-20230305221759217.png" alt="image-20230305221759217" style="zoom:80%;" />

<ol>
<li><p>录入新员工功能</p>
<p>录取新员工首先要获取新员工的信息,   包括姓名与人脸图片，首先需要打开摄像头，从摄像头中不断捕捉图像帧，检测到捕捉的图像帧有人脸信息之后，才将图片存入人脸；将图片存入本地之后，需要对存入的图片进行训练，将得到训练模型存入本地，方便下此调用。</p>
</li>
<li><p>打卡功能</p>
<p>加载训练好的模型文件，打开摄像头，从摄像头中不断捕获图像帧，识别到捕捉的图像帧有人脸信息后，对该图像帧进行人脸识别，并返回识别结果。</p>
</li>
</ol>
<h2 id="模块设计"><a href="#模块设计" class="headerlink" title="模块设计"></a>模块设计</h2><p>按照模块划分，人脸识别考勤系统可以分为用户界面模块，人脸识别模块，数据存储模块。</p>
<p>用户界面模块与用户和人脸识别模块进行交互。用户界面模块的功能包括：显示可视化界面及其对应的功能按钮、显示提示信息、读取图片并传入人脸识别模块、显示人脸识别模块传来的识别信息。</p>
<p>人脸识别模块是该系统的核心模块，它提供如下功能：</p>
<ol>
<li><p>人脸检测功能。主要为用户界面模块所调用，使其能够提供真正拥有人脸信息的图像。</p>
</li>
<li><p>生成存储图片的信息。为存储的图片生成对应的文件夹。</p>
</li>
<li><p>训练模型文件。将用户界面传过来的图片进行预处理，包括统一尺寸、灰度图与二值图的调整，然后进行模型训练，将训练好的模型传给数据存储模块。</p>
</li>
<li><p>人脸识别。读取数据存储模块提供的模型文件，对用户界面模块传来的人脸图片通过模型文件进行对比，将识别结果交付给用户界面模块，并将更新的信息传递给数据存储模块。</p>
</li>
</ol>
<p>数据存储模块与人脸识别模块进行交互。由于存在图片数据和员工信息数据，所以存储地点分为本地和数据库。本地负责存储员工人脸图片和模型文件，数据库负责存储员工姓名等信息。它的功能包括：存储信息、将数据传递给人脸识别模块、更新并保存从人脸识别模块传来的相关信息。</p>
<p>功能测试模块的功能包括调试、日志信息打印。</p>
<h1 id="系统实现"><a href="#系统实现" class="headerlink" title="系统实现"></a>系统实现</h1><h2 id="模块实现"><a href="#模块实现" class="headerlink" title="模块实现"></a>模块实现</h2><h3 id="用户界面模块"><a href="#用户界面模块" class="headerlink" title="用户界面模块"></a>用户界面模块</h3><p>用户界面模块是基于Java提供的原生套件Swing来实现的。其主要逻辑：提供一个唯一的主窗体，以及不同的面板，面板中显示所需要显示的各种信息与按键，面板显示在唯一主窗体上。当用户想要切换界面时，将唯一主窗体上现有的面板组件全部移除，创建新的所需要的面板，并放置在唯一主窗体上，通过这样的思路达到面板切换的功能。下面介绍主窗体与主要面板。</p>
<ol>
<li><p>主窗体</p>
<p>由于主窗体是全局唯一的，为了避免不必要的错误，使用单例模式创建主窗体类的对象，在主窗体类文件中创建其对象，并设置其类型为private static final，再设置该类的唯一构造方法为私有，对外只提供获取该对象指针的函数。主窗体提供的功能包括设置窗体关闭按钮监听、设置新面板的方法。</p>
</li>
<li><p>主面板</p>
<p>主面板提供的功能按钮包括打卡按钮和员工管理按钮。</p>
<p>打卡按钮监听：按下按钮后，调起摄像头并捕捉图像帧，通过人脸识别模块提供的人脸检测函数进行人脸检测，将含有人脸信息的图像传递给人脸识别模块进行人脸识别。</p>
<p>员工管理按钮监听：按下按钮后，进入员工管理面板。</p>
<p>主面板还包括一个信息提示框和摄像头实时显示框。在人脸识别模块将人脸识别的信息传递过来之后，主面板将该信息整合并显示到信息提示框上。当UI界面、摄像头实时显示框和打卡功能同时使用唯一主线程的时候，在按下打卡按钮进行人脸识别时，摄像头实时显示框会出现卡顿现象，这是由于不同功能同时使用主线程，导致主线程不得不来回中断以执行不同的功能。所以在实现的时候，另起一线程来完成摄像头实时显示的功能。</p>
<p>调起摄像头并获取摄像头的图像帧的功能可以通过OpenCV的jar包自带的操作摄像头相关的类来实现，也可以通过其他的jar包比如webcam来实现。考虑到摄像头需要实时显示在Swing提供的JPanel面板上，而webcam本来就提供继承于JPanel的WebcamPanel类，所以本系统采用webcam来实现摄像头相关功能。</p>
</li>
<li><p>员工管理面板</p>
<p>读取缓存类提供的员工信息，并将对应的信息显示在员工管理面板上，并提供返回主面板和转到录入新员工面板的按钮。</p>
</li>
<li><p>录入新员工面板</p>
<p>在该面板中完成新员工录入的功能。它包括一个姓名输入框，一个启动录入人脸功能的按钮，以及摄像头实时显示框。同样的，为了保证UI界面的流畅度，摄像头开启功能、录入人脸功能和摄像头实时显示功能采用异步的方式实现。</p>
<p>其中添加新员工功能流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230305221722587.png" alt="image-20230305221722587" style="zoom:80%;" />

<p>其中进行人脸检测的函数、将图片存入本地的函数都由人脸识别模块提供。</p>
</li>
</ol>
<h3 id="人脸识别模块"><a href="#人脸识别模块" class="headerlink" title="人脸识别模块"></a>人脸识别模块</h3><p>人脸识别模块所提供的功能有：保存人脸图片、引擎选择、人脸检测、人脸识别。</p>
<ol>
<li><p>保存人脸图片</p>
<p>人脸识别模块接收用户界面模块传来的人脸图片集合，将人脸图片存入本地。其流程为：</p>
<img src="D:/Program%20Files/Typora/img/image-20230305221652251.png" alt="image-20230305221652251" style="zoom:80%;" />

<p>其中拼音转换功能使用的是pinyin4j的jar包，该jar包可以对同音的中文汉字进行不同拼音的转化，还可以对于非中文汉字字符选择性不转化。</p>
</li>
<li><p>引擎选择</p>
<p>本系统支持2种引擎，一是虹软科技提供的人脸识别引擎，二是通过OpenCV提供的人脸识别接口实现的引擎，该接口提供3种人脸算法，分别为EigenFace、FisherFace以及LBPH。</p>
<p>本系统提供配置文件对引擎进行选择，只需修改配置文件中的值就可以进行引擎的切换。</p>
<p>两种引擎都实现了人脸检测和人脸识别的功能。</p>
</li>
<li><p>人脸检测</p>
<p>（1）虹软引擎的人脸检测。流程如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230305222840644.png" alt="image-20230305222840644" style="zoom:80%;" />

<p>其中，保存图像信息、人脸信息、人脸特征所需要的ImageInfo类、FaceInfo类和faceFeature类，以及对应的方法调用都来自于虹软引擎的开放API。</p>
<p>（2）基于OpenCV的人脸检测。其流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230305224809284.png" alt="image-20230305224809284" style="zoom:80%;" />

<p>需要注意的是，OpenCV人脸检测所得到的人脸检测结果为OpenCV提供的MatOfRect类，用于存储多个矩阵，也就是多张对输入图片进行检测并切分后的人脸图片，而虹软引擎最后的人脸特征为虹软人脸引擎API提供的FaceFeature类。但是由于这是人脸检测，所以只需要判断最后结果的有无，即对返回结果的判空即可。</p>
</li>
<li><p>人脸识别</p>
<p>人脸检测在本系统中只是起到一个优化系统的作用，真正实现考勤功能的是人脸识别功能。人脸识别功能可以分为两步，一是对目标图像进行训练，生成对应的模型文件，二是对所给定的图像进行比对，通过该图像上的人脸进行判别，进而确定此人的身份。</p>
<p>人脸识别功能需要对训练图像进行预分类，并设置每一类图像的标签之后，才能对给定的图像进行人脸识别，并返回标签。</p>
<p>而在本系统中，由于每个人的人脸图片的文件夹名称为相对应的人名的拼音，所以完全可以将每个人的人脸图片文件夹名称作为该类图像的标签。</p>
<p>（1）虹软人脸引擎的识别训练</p>
<p>​        流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230310183711893.png" alt="image-20230310183711893" style="zoom:80%;" />

<p>其中faceMap类型为Java提供的集合HashMap,   键值对类型为&lt;FaceFeature,   String&gt;，FaceFeature对应人脸特征类，String对应保存人名的拼音字符串。</p>
<p>虹软引擎不会生成对应的模型文件，每一次使用虹软引擎，都需要调用虹软引擎对应的函数生成人脸特征，然后进行比对。</p>
<p>（2）虹软人脸引擎的人脸识别</p>
<p>​        在拿到员工人脸特征集合faceMap后，只需要对当前的图片进行人脸特征的提取，然后挨个与faceMap中的人脸特征进行比较，取得最高匹配分数的FaceFeature对象对应的人名拼音，将其返回即可。由于虹软人脸识别引擎为一个商用引擎，所以它的API不会设置的太复杂。</p>
<p>（3）基于OpenCV的人脸引擎的人脸识别训练</p>
<p>​        整体来说，训练流程就是整理好图片与标签之间的关系，每一张人脸图片的操作流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230310193018128.png" alt="image-20230310193018128" style="zoom:80%;" />



<p>（4）基于OpenCV的人脸引擎的人脸识别</p>
<p>​        流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230310194445201.png" alt="image-20230310194445201" style="zoom:80%;" />

<p>其中预测方法调用的是OpenCV提供的API—predict方法。</p>
</li>
</ol>
<h3 id="数据存储模块"><a href="#数据存储模块" class="headerlink" title="数据存储模块"></a>数据存储模块</h3><p>数据存储模块中的存储位置有两个，一是本地文件夹，二是数据库。</p>
<ol>
<li><p>本地文件夹</p>
<p>本地文件夹存放的是yml训练模型文件和员工的人脸图片。OpenCV的基础人脸算法实现的方法相对于虹软人脸识别引擎而言都缺乏一定的稳定性，所以本系统使用多张人脸图片来训练。为了简化生成标签对应的方法的实现难度，每一个员工的人脸图片都存在各自的文件夹中，文件夹名以该员工的中文名对应的拼音来命名。</p>
</li>
<li><p>数据库</p>
<p>数据库的种类繁多，考虑到实际情况下可能会切换不同的数据库，所以采用设计模式工厂方法来实现数据库接口。本系统的其他类在调用数据库接口时，只需要通过工厂类提供的静态方法获取数据库连接即可。而在工厂类内部，仅需返回对应的继承了DAO类的具体子类实现所创建的对象。</p>
<p>在切换数据库时，只需实现对应的具体数据库的子类，然后在工厂方法种进行修改，达到解耦合的作用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DAOFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DAO <span class="title">getDAO</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DAOMySQLImpl();</span><br><span class="line">        <span class="comment">// return new SQLiteImpl;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>本系统与数据库的连接采用JDBC。在配置文件中写好数据库url地址、名称与密码，在具体的数据库实现子类中把对应的SQL语句通过JDBC传递给数据库，待其返回需要的数据即可。</p>
</li>
</ol>
<h2 id="算法设计"><a href="#算法设计" class="headerlink" title="算法设计"></a>算法设计</h2><h3 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h3><p>下面对特征脸算法进行分析。</p>
<p>由于机器天生只会执行命令，并不具备特别能够将不同的事物进行区分的能力，所以人工智能领域的大多数算法都是在尝试教会机器对给定的事物在人类提供的框架与指定的规则下进行分类，并根据得出的线性组合对未知的数据进行预测。而特征脸算法及其核心PCA算法，也是在对这种思想进行基于特定功能场景的落实。</p>
<p>人脸识别的目的是让机器能够识别出当前照片中的人脸是谁，其对象为图片，而现有计算机视觉框架下所定义的图片完全由数字组成，所以人脸识别的实现是可以基于人工智能基本思想的。可是由于其对象为图片，这种非结构化数据的维度过高，如64 * 64像素大小的RGB图像维度高达12288维，如此小而简单的图片都具有如此高的维度，如果直接对图片维度进行操作的话，是很困难的。所以特征脸算法引入了PCA算法，尝试对图片进行降维。特征脸算法的大致思路为：</p>
<p>（1）对图片进行预处理。如统一尺寸，进行光照归一化与灰度化。这一步其实是在对图片进行纵向降维，不改变图片的大小维度，而是改变图片的像素值，尽量缩减像素维度的取值范围。</p>
<p>（2）将图片转换为一个向量。将处理好的灰度化矩阵的每一行连在一起，构成一个行向量，再将其转为列向量。</p>
<p>（3）将人为分好类的图片集全部转为列向量之后，对其进行零值化处理，也就是将所有的列向量在各自的维度上求平均，再把每一个列向量减去该平均列向量。</p>
<p>（4）将处理好的所有列向量组合到一起，形成一个矩阵，计算该矩阵的协方差。</p>
<p>（5）计算协方差矩阵的特征值和特征向量。这些特征向量就是与原始图像维度一致的特征脸。</p>
<ol>
<li><p>协方差矩阵的计算</p>
<p>上述属于使用原始PCA算法所实现的特征脸算法，而实际上由于图片的维度过大，在对协方差矩阵求特征向量时耗时巨大，所以特征脸算法在实现的时候，是对维度为图片数量的协方差矩阵求特征向量，也就是原矩阵的转置乘原矩阵，在OpenCV的源码中，PCA算法也提供了对应的标志位让调用函数选择使用哪种方式进行协方差矩阵的求法。下面对scrambled式求法进行具体讲解。</p>
<p>对输入的图像集进行零值化处理后，所形成的n个列向量组合为一个矩阵，设该矩阵为<strong>X</strong>，矩阵为<strong>X</strong>的维度为m * n，其中n为输入的图像张数，m为图像像素点的数量。而如果按照原始PCA算法来设计，其协方差矩阵为<br>$$<br>C=XX^T<br>$$<br>这样求出来的协方差矩阵规模为m * m，由于m为像素点的数量，所以该协方差矩阵的规模是极大的，并不利于通过协方差矩阵求得特征值和特征向量，所以特征脸算法改用如下的方式球的协方差矩阵<br>$$<br>C’=X^TX<br>$$<br>通过这样的方式，协方差矩阵的规模变为n * n，由于在实际应用中，图片数量远远小于像素点数量，所以此举大大减小了协方差矩阵规模，极大地减小了后面通过特征值分解法或奇异值分解法计算特征值和特征向量所耗费的的时间和空间资源。</p>
<p>如果采用原始的PCA算法进行协方差矩阵的计算，其时间复杂度为O(nm<sup>2</sup>)，其中m为图像像素点的数量，因为这是一个m * n矩阵和一个n * m矩阵的矩阵相乘，为了得到协方差矩阵的一个元素，需要进行n次乘法，而协方差矩阵有m<sup>2</sup>个元素，所以总共需要nm<sup>2</sup>次乘法，所以其时间复杂度为O(nm<sup>2</sup>)。而如果使用特征脸法改变协方差矩阵的规模为n * n，则其时间复杂度为O(mn<sup>2</sup>)，时间成本大幅降低。</p>
<p>原始的PCA算法计算出的协方差矩阵的规模为m * m，所以其主要的空间消耗为O(m<sup>2</sup>)，而改良之后的协方差矩阵的规模为n * n，其主要的空间消耗为O(n<sup>2</sup>)，由于所用的图片集数量实际上远远小于图片维度，所以此举的改变是非常巨大的。</p>
<p>当然OpenCV对于协方差矩阵的乘法也是有着各种各样的优化的，比如通过SIMD指令集结合CPU的扩展寄存器的特性，在代码指令层面加速该过程。</p>
</li>
<li><p>计算特征值和特征向量</p>
<p>使用SVD算法对协方差矩阵进行计算，其步骤为：</p>
<p>(1) 对输入矩阵进行初步处理，例如去除均值、缩放等操作。 </p>
<p>(2) 初始化左右奇异向量，并计算初始残差。 </p>
<p>(3) 迭代计算左右奇异向量和残差，直到满足收敛条件。 </p>
<p>(4) 根据左右奇异向量和残差计算奇异值和对应的左右奇异向量。</p>
<p>迭代计算左右奇异向量和残差是最耗时的部分。具体来说，在每次迭代中，需要对输入矩阵进行一次旋转操作，以使得某个元素趋近于零。这个旋转操作需要对整个矩阵进行更新，因此时间复杂度为$O(mn)$。由于SVD算法需要迭代多次才能达到收敛条件，因此总的时间复杂度为$O(k\min(mn^2, m^2n))$，其中$k$是迭代次数，m和n为协方差矩阵的行数和列数。当$m \geq n$时，SVD类的时间复杂度为$O(mn^2)$；当$m &lt; n$时，JacobiSVD类的时间复杂度为$O(m^2n)$。在实际应用中，可以根据m和n的大小和精度进行不同的策略选择，如果使用了上述特征脸的特殊考量，则m&gt;&gt;n，所以其在特征脸算法中的时间复杂度为$O(mn^2)$。</p>
</li>
</ol>
<p>此时不难发现，在这种思路下，PCA算法计算协方差矩阵的时间复杂度和计算特征向量的时间复杂度相同，所以特征脸算法的总时间复杂度为$O(mn^2)$。</p>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>本系统从整体而言可使用虹软人脸识别引擎和基于OpenCV接口的人脸识别引擎。虹软人脸识别引擎识别准度高，识别速度快，但是尽管本系统使用的虹软引擎为离线版，其具体的实现算法也是不开源的，对于面向Java的接口，若要追其源码，只能追到关键字native所实现的c++层面所提供的接口函数，而在c++层面，其算法也是不开源的。但是OpenCV为开源项目，所有的实现只要不过于底层，都是可以溯源的，所以下面简要分析OpenCV对于EigenFace的实现。本系统使用纯Java语言开发，通过OpenCV提供的jar包来调用对应的接口，但是OpenCV是使用c++编写的，它对Java和Python都只提供对应的接口，所以要分析OpenCV对于EigenFace的实现源码，需要深入c++语言层面。</p>
<p>OpenCV4提供了较为稳定的基于深度学习的人脸识别类FaceRecognizerSF，但其对扩展包中人脸识别总类FaceRecognizer并不向后兼容。现在的OpenCV的版本中的基础人脸算法因为其不稳定性，被分到了OpenCV的扩展包opencv_contrib里。</p>
<p>对于人脸模块的类文件，其类图如下</p>
<img src="D:/Program%20Files/Typora/img/image-20230310204422690.png" alt="image-20230310204422690" style="zoom:80%;" />

<ol>
<li><p>eigen_faces.cpp</p>
<p>EigenFace算法的实现的路径为opencv_contrib\modules\face\src\eigen_faces.cpp。EigenFaceRecognizer继承于FaceRecognizer，所以它必然需要重写FaceRecognizer的父类训练方法train和预测方法predict。</p>
<p>（1）train方法</p>
<p>​        整体来看，在进行了一系列的判空判错操作之后，将主要的计算任务交给了PCA类，当获取到特征向量和特征值之后，把输入矩阵映射到PCA子空间中，然后保存到变量当中,以供预测函数使用。其流程图如下：</p>
<img src="D:/Program%20Files/Typora/img/image-20230310213051286.png" alt="image-20230310213051286" style="zoom:80%;" />

<p>需要注意的是，train方法中最后将输入矩阵映射到子空间所使用的是LDA类的subspaceProject方法。</p>
<p>（2）predict方法</p>
<p>​        predict方法相较于train方法而言较为简单，其大体流程为：</p>
<img src="D:/Program%20Files/Typora/img/image-20230310220243077.png" alt="image-20230310220243077" style="zoom:80%;" />

<p>而其进行PCA子空间的映射也是使用的LDA类的subspaceProject方法。</p>
<p>以上就是OpenCV对于EigenFace算法的c++实现，eigen_face.cpp整体来看是业务代码居多，而且其算法的核心—PCA相关的实现代码并没有展现，要深入研究EigenFace算法，还需要深入OpenCV对于PCA算法的c++实现中去。</p>
</li>
<li><p>pca.cpp</p>
<p>pca.cpp的路径为opencv\sources\modules\core\src\pca.cpp，该源文件中实现了多个方法，而其对于PCA算法的核心方法，是该文件的PCA类的构造方法所调用的operator方法。</p>
<p>通过重载的方式，operator方法可以选择保留的主成分是通过最大主成分数maxComponents或者差异百分比retainedVariance来确定，这里对使用前者的重载方法进行分析。</p>
<p>operator方法的主要工作包括：生成协方差运算标志位covar_flags、生成均值向量、设置协方差矩阵运算方式（normal或者scramble）等等。具体而言，</p>
<p>（1）通过传入的flags参数判断输入矩阵为行矩阵或者列矩阵，通过该判断生成对应的均值向量，并设置covar_flags标志位；</p>
<p>（2）确定主成分数为样本量、数据量和传入的主成分数三者中的最小值。</p>
<p>（3）设置均值向量标志位，若输入均值向量非空，则不计算均值向量，直接使用输入均值向量，并设置其标志位。</p>
<p>（4）将输入矩阵、协方差矩阵、均值向量、标志位和矩阵类型传入calcCovarMatrix方法中进行计算。</p>
<p>此处反复提及的标志位covar_flags为一个整型变量，当要往该变量中传入某个信息时，只需要提前规划好该整型变量的位模式，在使用时将该变量与想要传递的信息的编码相与，即可准确保存信息，类似于位图。</p>
<p>operator方法中并没有具体的协方差矩阵的运算代码，所以继续深入。</p>
</li>
<li><p>matmul.dispatch.cpp</p>
<p>calcCovarMatrix方法在核心包中的路径为\source\modules\core\src\matmul.dispatch.cpp，但是在该方法中，仅仅只是通过传递来的标志位确定其均值向量，又把计算任务传递给了mulTransposed方法。在mulTransposed方法中，对矩阵规模进行判断，如果输入矩阵与输出矩阵的行和列都大于100，则直接使用gemm通用矩阵乘法进行计算，反之，则通过getMulTransposedFunc方法确定了输入矩阵输出矩阵的类型和协方差运算方式后，调用MulTransposedX方法进行真正的计算，其中X为L或者R，二者的选择取决于其标志位aTa。</p>
</li>
<li><p>matmul.simd.hpp</p>
<p>上述源文件matmul.dispatch.cpp，通过其名称可知，其主要作用为分发，分发对于协方差矩阵计算而言，就是矩阵精度和协方差运算方式，另一方面，分发而源文件matmul.simd.hpp，则在做真正的运算工作，因为其过于底层，所以对运算速度的要求很高，自然需要进行一些底层的优化。</p>
<p>下面对MulTransposedR方法进行解析。</p>
<p>MulTransposedR方法，也就是通过scramble方式进行的协方差矩阵运算，从数学层面来看，也就是矩阵的转置乘矩阵，从代码层面来看，也就是矩阵的列乘矩阵的列。</p>
<p>（1）数据预处理</p>
<p>数据预处理包括获取输入矩阵和输出矩阵的列数、获取均值向量的大小、生成对应的缓冲区与指针，如果均值向量的列数小于数据矩阵的列数，则把申请的缓冲区内存大小扩大5倍，并将原均值矩阵的值放于缓冲区上，并将原均值矩阵指针指向对应的开头位置。此时内存图如下，</p>
<img src="D:/Program%20Files/Typora/img/image-20230312223427701.png" alt="image-20230312223427701" style="zoom:80%;" />

<p>col_buf为缓冲区的头指针，del_buf为缓冲区上均值矩阵的指针。</p>
<p>（2）运算过程</p>
<p>MulTransposedR方法对于协方差矩阵的运算从代码层面来看为矩阵列乘矩阵列，所以运算过程首先将矩阵的一列对应减去均值向量，然后放于缓冲区的[col_buf,   del_buf]处，再通过SIMD指令集对乘法过程进行优化，也就是一次将两个值取出并保存于扩展寄存器中，让一条指令执行两项运算，优化运算常数时间。通过两个扩展寄存器与另一个扩展寄存器相乘的操作，可以使得在一次迭代中用两条指令进行4次乘法。而如果没有SIMD优化，则直接创建四个变量进行乘法。为保证跳跃的4次乘法的操作不发生数组下标越界，则只能循环执行的长度为矩阵列数-4。</p>
<p>最后，运算结果乘以对应的缩放尺度，双双存入输出矩阵对应的位置即可。</p>
<img src="D:/Program%20Files/Typora/img/image-20230312222627362.png" alt="image-20230312222627362" style="zoom:80%;" />

<p>整体来看，在矩阵规模较小的情况下，优化算法常数时间的举措有两个，一是使用SIMD指令集优化，让一条指令执行两次运算，二是不使用上层数据结构，直接使用内存读写，加快读写速度。</p>
<p>而在数据规模较大的时候所使用的gemm运算方法，则是各个底层部件竞相优化的对象，在OpenCV的硬件层面，可以通过HAL对其进行优化，对应宏CALL_HAL，实现者可以将自己的实现把hal_replacement.hpp替换掉。也可以使用基础方法和CPU最优选方法，分别对应宏CV_GEMM_BASELINE_ONLY和CV_CPU_DISPATCH。使用 CV_CPU_DISPATCH 可以根据 CPU 架构的不同来选择最优的代码实现。比如在 x86 架构上，OpenCV 中的一些函数可以通过 SSE 或 AVX 指令集来加速执行，而在 ARM 架构上，可以通过 NEON 指令集来加速执行。</p>
</li>
</ol>
<h1 id="系统测试"><a href="#系统测试" class="headerlink" title="系统测试"></a>系统测试</h1><h2 id="测试1"><a href="#测试1" class="headerlink" title="测试1"></a>测试1</h2><p>由于本系统集成了虹软人脸识别引擎和基于OpenCV的人脸识别引擎，又因为虹软引擎在人脸检测和人脸识别等方面相对于基于OpenCV的人脸识别引擎而言过于优良，所以本测试为“在虹软引擎检测出所捕获的摄像头照片具有人脸特征的前提下，判别各个引擎未识别出员工的帧数”。</p>
<p>测试结果：</p>
<table>
<thead>
<tr>
<th>引擎</th>
<th>平均未识别帧数</th>
</tr>
</thead>
<tbody><tr>
<td>虹软引擎</td>
<td>0~1帧</td>
</tr>
<tr>
<td>LBPH</td>
<td>2~3帧</td>
</tr>
<tr>
<td>FisherFace</td>
<td>9~10帧</td>
</tr>
</tbody></table>
<h2 id="测试2"><a href="#测试2" class="headerlink" title="测试2"></a>测试2</h2><p>测试额定功率3.5W的照明灯全功率开启时获取图片进行训练，关闭时检测的结果。</p>
<table>
<thead>
<tr>
<th>引擎</th>
<th>平均未识别帧数</th>
</tr>
</thead>
<tbody><tr>
<td>虹软引擎</td>
<td>2~3帧</td>
</tr>
<tr>
<td>LBPH</td>
<td>5~6帧</td>
</tr>
<tr>
<td>FisherFace</td>
<td>11~12帧</td>
</tr>
</tbody></table>
<p>从上述测试来看，FisherFace和LBPH对于光照强度变化并不敏感。</p>
<h2 id="测试3"><a href="#测试3" class="headerlink" title="测试3"></a>测试3</h2><p>测试非正脸时，平均未识别出的帧数。垂直倾斜的含义是使用人们常说的侧脸去面对摄像头，水平倾斜即面对摄像头歪头。</p>
<table>
<thead>
<tr>
<th>引擎</th>
<th>人脸垂直倾斜角度&gt;30度的平均未识别帧数</th>
<th>人脸水平倾斜角度&gt;30度的平均未识别帧数</th>
</tr>
</thead>
<tbody><tr>
<td>虹软引擎</td>
<td>0~1帧</td>
<td>0~1帧</td>
</tr>
<tr>
<td>LBPH</td>
<td>未能识别</td>
<td>未能识别</td>
</tr>
<tr>
<td>FisherFace</td>
<td>未能识别</td>
<td>未能识别</td>
</tr>
</tbody></table>
<p>从上述测试来看，OpenCV的人脸算法只是提供基础的人脸识别功能，对于人脸识别可能遇见的复杂场景所需要的容错率不足，在各个方面完全不能和商业引擎相提并论。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/04/excalidraw/bi-ye-she-ji/"><img class="prev-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info"></div></div></a></div><div class="next-post pull-right"><a href="/2023/03/01/shui-mian-yan-jiu/shui-mian-yan-jiu-jie-guo/"><img class="next-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info"></div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1"><span class="toc-text">系统设计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%9F%E8%83%BD%E8%AE%BE%E8%AE%A1"><span class="toc-text">功能设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9D%97%E8%AE%BE%E8%AE%A1"><span class="toc-text">模块设计</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0"><span class="toc-text">系统实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0"><span class="toc-text">模块实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2%E6%A8%A1%E5%9D%97"><span class="toc-text">用户界面模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9D%97"><span class="toc-text">人脸识别模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97"><span class="toc-text">数据存储模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1"><span class="toc-text">算法设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-text">算法分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-text">算法实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E6%B5%8B%E8%AF%95"><span class="toc-text">系统测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%951"><span class="toc-text">测试1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%952"><span class="toc-text">测试2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%953"><span class="toc-text">测试3</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><div id="footer-wrap"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>